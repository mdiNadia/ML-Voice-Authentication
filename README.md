
# ğŸ™ï¸ Voice Authentication & Speaker Classification System

This project is a **machine learning-based voice authentication system** developed as the final course project for **MSc Artificial Intelligence** at **University of Tehran (2025)**. It focuses on **speaker identification**, **gender classification**, and **voice clustering** using advanced **audio signal processing** and **deep learning** techniques.

---

## ğŸ“Œ Project Goals

- âœ… Build an **intelligent system** to classify speaker identity and gender using voice samples.
- âœ… Compare **open-set** and **closed-set authentication** mechanisms.
- âœ… Extract powerful audio features (MFCC, Log-Mel, Spectral Contrast, etc.).
- âœ… Handle real-world challenges like **noise**, **voice spoofing**, and **emotion-based voice variation**.
- âœ… Apply **ML/DL models** to identify and cluster voices effectively.

---

## ğŸ§  Features & Techniques

### ğŸ§ Audio Preprocessing
- Band-pass filtering (100â€“8000 Hz)
- LUFS normalization
- Silence removal using RMS
- Duration trimming

### ğŸ” Feature Extraction
- **Log-Mel Spectrogram**
- **MFCC (Mel Frequency Cepstral Coefficients)**
- Spectral Centroid & Contrast
- Zero Crossing Rate (ZCR)
- LPC / PLP
- Energy features (frame-wise)

### ğŸ§ª Machine Learning Models
- Support Vector Machines (SVM)
- KMeans & GMM (for clustering)
- PCA / Feature Reduction
- Feature Selection & Validation (Silhouette Score, Cross-validation)

### ğŸ¤– Deep Learning
- CNNs for spectrogram image classification
- RNNs (LSTM/GRU) for time-series voice patterns
- Contrastive Loss & Embedding Adaptation for open-set

---

## ğŸ›  Tech Stack

| Category | Tools / Libraries |
|---------|-------------------|
| Language | Python |
| Audio | `librosa`, `soundfile`, `pyloudnorm` |
| ML / DL | `scikit-learn`, `PyTorch`, `Torch`, `Pandas`, `NumPy` |
| Visualization | `Matplotlib`, `Seaborn` |
| Evaluation | `Silhouette Score`, `Confusion Matrix`, `Entropy Threshold` |

---

## ğŸ“ Project Structure

```
ml_project/
â”œâ”€â”€ Audio_Scripts/
â”‚   â”œâ”€â”€ preprocessing.py         # Noise reduction, silence removal
â”‚   â”œâ”€â”€ feature_extraction.py    # MFCC, Log-Mel, spectral features
â”‚   â””â”€â”€ audio_utils.py           # Dataset utilities
â”œâ”€â”€ Audio_GenderDetection/       # Gender classification
â”œâ”€â”€ Audio_Authentication/        # Speaker recognition (open/closed set)
â”œâ”€â”€ Audio_Clustering/            # Clustering voice features
â””â”€â”€ data/
    â””â”€â”€ raw/                     # ~473 labeled voice files
```

---

## ğŸ“Š Dataset Summary

- **473 audio samples** (~35.5 hours)
- **114 speakers** (86 male, 28 female)
- Files manually curated, normalized, and labeled
- Each speaker: 3Ã— 3-second voice clips for training/testing
- Clustering evaluated using **Silhouette Score**

---

## ğŸ¯ Results & Highlights

- Achieved high accuracy in gender classification via MFCC & Log-Mel.
- Successfully implemented **open-set authentication** using similarity learning.
- Applied **deep learning** models (CNN, GRU) with meaningful performance gains.
- Preprocessed audio signals show improved model robustness in noisy conditions.

---

## ğŸ§ª Sample Visualizations

<p align="center">
  <img src="examples/mfcc_example.png" width="400"/> 
  <img src="examples/logmel_example.png" width="400"/>
</p>

---

## ğŸ‘¥ Contributors

- **Omid Molaei**
- **Nadie Mohammadi**
- **Fatemeh Sadri**

Supervised by: *MSc AI â€“ Faculty of Engineering, University of Tehran*

---

## ğŸ“Œ How to Use

1. Clone this repo:
   ```bash
   git clone https://github.com/yourusername/voice-auth-ml.git
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run gender detection:
   ```bash
   python Audio_GenderDetection/gender_model.py
   ```
4. For clustering:
   ```bash
   python Audio_Clustering/kmeans_clustering.py
   ```

---

## ğŸ“œ License

MIT License â€” for academic and research use.
