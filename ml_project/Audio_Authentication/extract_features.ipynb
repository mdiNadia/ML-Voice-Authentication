{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746c8cd2-b132-4a84-ae42-4aef049d6398",
   "metadata": {},
   "source": [
    "## 1. Import required Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11cafa85-c865-4bb8-a5dc-29d34e2ccf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from IPython.display import Audio\n",
    "from pyloudnorm import Meter, normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f3128-42df-4576-bff6-e2fc89b54683",
   "metadata": {},
   "source": [
    "## 2. Define some required functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b18ba75-d5dc-4b48-ac73-79a7681991de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_student_id(filename):\n",
    "    pattern = r\"\\d{9}\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def denoise_speech_bandpass(audio_data, sr, lowcut, highcut, order=5):\n",
    "  nyq = 0.5 * sr\n",
    "  low = lowcut / nyq\n",
    "  high = highcut / nyq\n",
    "  b, a = butter(order, [low, high], btype='band')\n",
    "  denoised_audio = filtfilt(b, a, audio_data)\n",
    "  return denoised_audio\n",
    "\n",
    "\n",
    "def remove_silence(audio_data, sr, threshold=0.05, frame_length=4096, hop_length=512):\n",
    "    rms = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    frames_above_threshold = np.where(rms > threshold)[0]\n",
    "    non_silent_segments = []\n",
    "    for i in range(len(frames_above_threshold)):\n",
    "        start_sample = frames_above_threshold[i] * hop_length\n",
    "        end_sample = min((frames_above_threshold[i] + 1) * hop_length, len(audio_data))  # Prevent exceeding audio length\n",
    "        non_silent_segments.append(audio_data[start_sample:end_sample])\n",
    "    if len(non_silent_segments) > 0:\n",
    "      non_silent_audio = np.concatenate(non_silent_segments)\n",
    "    else:\n",
    "      non_silent_audio = audio_data\n",
    "    return non_silent_audio\n",
    "\n",
    "\n",
    "def normalize_audio(audio_data, sr,  target_lufs=-14):\n",
    "  meter = Meter(sr) # create BS.1770 meter\n",
    "  loudness = meter.integrated_loudness(audio_data)\n",
    "  loudness_normalized_audio = normalize.loudness(audio_data, loudness, target_lufs)\n",
    "  return loudness_normalized_audio\n",
    "\n",
    "\n",
    "def preprocess_audio(audio_data, sr=22050):\n",
    "  y_denoised = denoise_speech_bandpass(audio_data, sr, lowcut=100, highcut=8000, order=6)\n",
    "  y_normalized = normalize_audio(y_denoised, sr, -14)\n",
    "  non_silent_audio = remove_silence(y_normalized, sr, threshold=0.05, frame_length=4096, hop_length=512)\n",
    "  return non_silent_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdc552-a809-499d-80e4-652a75c2a497",
   "metadata": {},
   "source": [
    "## 3. Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed6221c-2b00-40bb-8e11-fa365bbd7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(segment, target_sr):\n",
    "    mfcc = librosa.feature.mfcc(y=segment, sr=target_sr, n_mfcc=13)\n",
    "    mfcc = np.mean(mfcc.T, axis=0)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=segment, sr=target_sr)\n",
    "    spectral_contrast = np.mean(spectral_contrast, axis = 1)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=segment)\n",
    "    zero_crossing_rate = np.mean(zero_crossing_rate)\n",
    "    rms = np.mean(librosa.feature.rms(y=segment).T, axis=0)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=segment, sr=target_sr)\n",
    "    spectral_centroid = np.mean(spectral_centroid)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=segment, sr=target_sr)\n",
    "    spectral_bandwidth = np.mean(spectral_bandwidth)\n",
    "\n",
    "    feature_data = {\n",
    "        'Mfcc_' + str(i+1): mfcc[i] for i in range(len(mfcc))\n",
    "    }\n",
    "    \n",
    "    feature_data.update({\n",
    "        'Spectral_Contrast_' + str(i+1): spectral_contrast[i] for i in range(len(spectral_contrast))\n",
    "    })\n",
    "    \n",
    "    feature_data['Zero_Crossing_Rate'] = zero_crossing_rate\n",
    "    feature_data['RMS_Energy'] = rms\n",
    "    feature_data['Spectral_Centroid'] = spectral_centroid\n",
    "    feature_data['Spectral_Bandwidth'] = spectral_bandwidth\n",
    "\n",
    "    return feature_data\n",
    "\n",
    "def process_audio(audio_directory, output_file, target_sr=22050, segment_duration=4.0):\n",
    "    np.random.seed(42)\n",
    "    student_info = []\n",
    "    for filename in os.listdir(audio_directory):\n",
    "        if 'female' in filename.lower():\n",
    "            label = 'female'\n",
    "        elif 'male' in filename.lower():\n",
    "            label = 'male'\n",
    "        else:\n",
    "            continue\n",
    "        student_id = extract_student_id(filename)\n",
    "        student_info.append((student_id, label, filename))\n",
    "    df_info = pd.DataFrame(student_info, columns=['student_id', 'gender', 'filename'])\n",
    "    male_students = df_info[df_info['gender'] == 'male']['student_id'].unique()\n",
    "    female_students = df_info[df_info['gender'] == 'female']['student_id'].unique()\n",
    "    min_count = min(len(male_students), len(female_students))\n",
    "    balanced_male_students = np.random.choice(male_students, min_count, replace=False)\n",
    "    balanced_female_students = np.random.choice(female_students, min_count, replace=False)\n",
    "    balanced_student_ids = np.concatenate((balanced_male_students, balanced_female_students))\n",
    "    df_balanced = df_info[df_info['student_id'].isin(balanced_student_ids)]\n",
    "    feature_columns = ['filename', 'label', 'student_id'] + \\\n",
    "                      ['Mfcc_' + str(i) for i in range(1, 14)] + \\\n",
    "                      ['Spectral_Contrast_' + str(i) for i in range(1, 8)] + \\\n",
    "                      ['Zero_Crossing_Rate', 'RMS_Energy', 'Spectral_Centroid', 'Spectral_Bandwidth']\n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=feature_columns)\n",
    "        writer.writeheader()\n",
    "        for _, row in df_balanced.iterrows():\n",
    "            label = row['gender']\n",
    "            student_id = row['student_id']\n",
    "            filename = row['filename']\n",
    "            y, sr = librosa.load(os.path.join(audio_directory, filename), offset=1.0, duration=500.0, sr=target_sr)\n",
    "            y = preprocess_audio(y, sr=sr)\n",
    "            segment_length = int(segment_duration * sr)\n",
    "            num_segments = len(y) // segment_length\n",
    "            for i in range(num_segments):\n",
    "                start = i * segment_length\n",
    "                end = start + segment_length\n",
    "                segment = y[start:end]\n",
    "                feature_data = extract_features(segment, target_sr)\n",
    "                feature_data['filename'] = filename + f'_{i}'\n",
    "                feature_data['label'] = label\n",
    "                feature_data['student_id'] = student_id\n",
    "                writer.writerow(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edffb066-b28c-4e9e-8dad-29c76257b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pyloudnorm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='pyloudnorm')\n",
    "\n",
    "output_file = 'final_Audio_dataset.csv'\n",
    "process_audio('../Data/raw', output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f700814d-9052-49ee-a894-fa00e774b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      filename label  student_id      Mfcc_1      Mfcc_2  \\\n",
      "0  hw1_q2_610399205_male.mp3_0  male   610399205  -94.829977  122.175083   \n",
      "1  hw1_q2_610399205_male.mp3_1  male   610399205 -123.197408  131.659141   \n",
      "2  hw1_q2_610399205_male.mp3_2  male   610399205 -122.910702  141.014834   \n",
      "3  hw1_q2_610399205_male.mp3_3  male   610399205 -140.025639  126.584783   \n",
      "4  hw1_q2_610399205_male.mp3_4  male   610399205 -127.307332  122.204455   \n",
      "\n",
      "      Mfcc_3     Mfcc_4     Mfcc_5     Mfcc_6     Mfcc_7  ...  \\\n",
      "0 -68.000374  47.507958 -14.407363 -13.427573 -23.064053  ...   \n",
      "1 -61.479495  44.792372  -7.927916 -10.119547 -21.518692  ...   \n",
      "2 -67.712628  39.928565 -14.785694  -7.251495 -24.902940  ...   \n",
      "3 -53.874062  40.963797  -5.784167  -5.752144 -22.515332  ...   \n",
      "4 -61.316071  54.882303  -0.544779 -11.455723 -28.317545  ...   \n",
      "\n",
      "   Spectral_Contrast_2  Spectral_Contrast_3  Spectral_Contrast_4  \\\n",
      "0            16.537672            17.337876            15.638074   \n",
      "1            16.173748            17.615650            15.370934   \n",
      "2            15.759529            17.226226            15.636203   \n",
      "3            15.341300            15.522699            14.462609   \n",
      "4            17.254408            17.243651            14.808253   \n",
      "\n",
      "   Spectral_Contrast_5  Spectral_Contrast_6  Spectral_Contrast_7  \\\n",
      "0            18.102693            23.265461            66.736837   \n",
      "1            17.944107            21.722387            64.664952   \n",
      "2            18.222485            21.671965            63.307834   \n",
      "3            18.687998            22.817218            61.284887   \n",
      "4            19.110663            23.740752            67.221951   \n",
      "\n",
      "   Zero_Crossing_Rate    RMS_Energy  Spectral_Centroid  Spectral_Bandwidth  \n",
      "0            0.105971  [0.24632083]        1911.823347         1581.462113  \n",
      "1            0.079931  [0.21608743]        1656.721908         1499.382229  \n",
      "2            0.096313  [0.19001988]        1707.593297         1448.149975  \n",
      "3            0.099141  [0.16602059]        1857.183068         1591.809683  \n",
      "4            0.096767  [0.21153131]        1830.105791         1537.769633  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(output_file)\n",
    "\n",
    "print(dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
