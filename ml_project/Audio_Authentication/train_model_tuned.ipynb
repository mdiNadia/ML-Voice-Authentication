{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyevF_Qee1go"
   },
   "source": [
    "### Load the dataset from a CSV file and Create DataFrame\n",
    "Print the first few rows of the DataFrame to quickly inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "U1zw2eNnJrtc",
    "outputId": "4970a0ef-073c-4a3e-a7a1-f435822e2817"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the downloaded CSV file\n",
    "data = pd.read_csv('final_Audio_dataset.csv')\n",
    "print(\"Loaded Data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYPVZ45KftE1"
   },
   "source": [
    "Initially, the values in the RMS_Energy column are stored as strings, and they contain square brackets. This format is not suitable for numerical analysis, and hence, we need to clean and convert the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5v12rKXFaJb5"
   },
   "outputs": [],
   "source": [
    "data['RMS_Energy'] = data['RMS_Energy'].astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lri_fIIK017U"
   },
   "source": [
    "# Utills\n",
    "Required Functions\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H42GSrjnkhf"
   },
   "source": [
    "###   **K_fold_Crossvalidation Function**:  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "  *  This function provides an efficient way to compare classification models and evaluate various features and feature reduction techniques.\n",
    "\n",
    "  *   Using the KFold class from sklearn.model_selection, the data is split into k folds (default is 5). This ensures that each fold is used as a test set once, and as part of the training set k-1 times.\n",
    "\n",
    "  *   Standard scaling is applied to the feature sets using StandardScaler to normalize the data\n",
    "  *   If a feature reduction function is provided, we fit it using the training data and then apply it to the test data. This step ensures that the feature reduction technique is appropriately trained on the training set before being applied to unseen test data.\n",
    "  *  The average accuracy score across all folds are calculated to provide an overall performance metric. Additionally, the average confusion matrix is plotted to visualize the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7ZNrdf_kYWtk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def k_fold_cross_validation(df, feature_names, target_name, model, feature_reduction_func, k=5):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation on the given data.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input data frame.\n",
    "    feature_names (list): List of feature column names.\n",
    "    target_name (str): The name of the target column.\n",
    "    model: The classification model to be used.\n",
    "    feature_reduction_func: The feature reduction function to be applied.\n",
    "    k (int): The number of folds for cross-validation (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    float: The average accuracy score across all folds.\n",
    "    \"\"\"\n",
    "    X = df[feature_names]\n",
    "    y = df[target_name]\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Feature reduction\n",
    "        if(feature_reduction_func):\n",
    "          X_train_scaled = feature_reduction_func.fit_transform(X_train_scaled, y_train)\n",
    "          X_test_scaled = feature_reduction_func.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "\n",
    "        #test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        confusion_matrices.append(conf_matrix)\n",
    "\n",
    "    # Calculate average accuracy\n",
    "    avg_accuracy = np.mean(accuracies)*100\n",
    "    std_accuracy = np.std(accuracies)*100\n",
    "\n",
    "    # Plot the average confusion matrix\n",
    "    avg_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.heatmap(avg_conf_matrix, annot=True, fmt='.2f', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Average Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return avg_accuracy, std_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mvciaHy1Ntj"
   },
   "source": [
    "### **Visualization of Cross-Validation Results**\n",
    "### **Plot_Results_Barchart**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "To effectively compare the performance of various classification models and feature reduction techniques, we utilize a bar chart visualization. The Plot_Results_Barchart function is designed to generate and display these bar charts, providing clear and intuitive insights into the cross-validation results.\n",
    "\n",
    "For each feature reduction method, the function filters the results and plots a bar chart showing the mean accuracy of different models for each feature set. The maximum accuracy for each feature reduction method is printed, and bars with the highest accuracy are highlighted with red edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X-r2WvtIe795"
   },
   "outputs": [],
   "source": [
    "def Plot_Results_Barchart(results_df):\n",
    "\n",
    "  # List of feature reduction methods\n",
    "  feature_reductions = results_df['Feature Reduction'].unique()\n",
    "\n",
    "  # Set a pleasing color palette\n",
    "  sns.set_palette(\"Set2\")\n",
    "\n",
    "  # Loop to plot bar charts for each feature reduction method\n",
    "  for reduction in feature_reductions:\n",
    "      # Filter data for the current feature reduction method\n",
    "      filtered_results = results_df[results_df['Feature Reduction'] == reduction]\n",
    "      max_value = filtered_results['Mean Accuracy'].max()\n",
    "      print(f\"Maximum accuracy if feature reduction({reduction}): {max_value:.2f}%\")\n",
    "\n",
    "      # Plot the bar chart\n",
    "      plt.figure(figsize=(7, 5))\n",
    "      ax = sns.barplot(x='Feature Set', y='Mean Accuracy', hue='Model', data=filtered_results, errorbar=None, width=0.4)\n",
    "\n",
    "\n",
    "      # Add solid lines around each bar\n",
    "      for bar in ax.patches:\n",
    "          if bar.get_height() == max_value:\n",
    "              bar.set_edgecolor('red')\n",
    "              bar.set_linewidth(2)\n",
    "          else:\n",
    "              bar.set_edgecolor('black')\n",
    "              bar.set_linewidth(0.5)\n",
    "\n",
    "      # Set titles and labels\n",
    "      plt.title(f'Cross-Validation Mean Accuracy for Different Models ({reduction})', fontsize=10)\n",
    "      plt.xlabel('Feature Set', fontsize=8)\n",
    "      plt.ylabel('Mean Accuracy', fontsize=8)\n",
    "      plt.ylim(0, 100)\n",
    "      plt.xticks(fontsize=8)\n",
    "      plt.yticks(fontsize=8)\n",
    "      plt.legend(title='Model', loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=3, fontsize=8)\n",
    "\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj3-oqVcqP0_"
   },
   "source": [
    "### **Classification Using Different Models, Feature Reduction, and Feature Sets**\n",
    "### **Run_Classification**\n",
    "\n",
    "---\n",
    "The Run_Classification function is a comprehensive approach designed to evaluate the performance of various classification models using different feature sets and feature reduction techniques. This function leverages *k-fold cross-validation*(**k=4**) to provide robust performance metrics for each combination of model, feature set, and feature reduction method.\n",
    "*   Various classification models are defined for evaluation:\n",
    "  *   K-Nearest Neighbors (KNN)\n",
    "  *   Logistic Regression\n",
    "  *   Support Vector Machine (SVM)\n",
    "\n",
    "\n",
    "*   Feature Reduction Techniques:\n",
    "  *   Linear Discriminant Analysis (LDA)\n",
    "  *   Principal Component Analysis (PCA)\n",
    "  *   No feature reduction (None)\n",
    "\n",
    "*   Defining Feature Sets:\n",
    "  *   mfcc_features: Mel-Frequency Cepstral Coefficients (MFCC) features.\n",
    "  *   spectral_contrast_features: Spectral Contrast features.\n",
    "  *   combined_features: A combination of MFCC and Spectral Contrast features.\n",
    "  *   time_features: Time-domain features such as Zero Crossing Rate and RMS Energy.\n",
    "  *   Spec_cent_Bw: Spectral Centroid and Spectral Bandwidth features.\n",
    "  *   all_features: A combination of all the above feature sets.\n",
    "\n",
    "The results DataFrame, containing the performance metrics for each combination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QFRhFeOJZJpW"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def Run_Classification(balanced_dataFrame):\n",
    "  # Define the feature sets\n",
    "  mfcc_features = [f'Mfcc_{i+1}' for i in range(13)]\n",
    "  spectral_contrast_features = [f'Spectral_Contrast_{i+1}' for i in range(7)]\n",
    "  combined_features = mfcc_features + spectral_contrast_features\n",
    "  time_features = ['Zero_Crossing_Rate',\t'RMS_Energy']\n",
    "  Spec_cent_Bw = ['Spectral_Centroid',\t'Spectral_Bandwidth']\n",
    "  all_features = combined_features + time_features + Spec_cent_Bw\n",
    "\n",
    "  balanced_dataFrame['RMS_Energy'] = balanced_dataFrame['RMS_Energy'].astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False).astype(float)\n",
    "\n",
    "  # Define the target column\n",
    "  target_column = 'class'\n",
    "\n",
    "  # Define the models\n",
    "  models = {\n",
    "      'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "      'Logistic Regression': LogisticRegression( max_iter=200, random_state= 42),\n",
    "      'SVM': SVC(kernel='linear', random_state=42)\n",
    "  }\n",
    "\n",
    "  # Define the feature sets\n",
    "  feature_sets = {\n",
    "      'time_domain_features' : time_features,\n",
    "      'MFCC': mfcc_features,\n",
    "      'Spectral Contrast': spectral_contrast_features,\n",
    "      'MFCC&Sp_Contrast': combined_features,\n",
    "      'Spec_Cent&BW': Spec_cent_Bw,\n",
    "      'all_features' : all_features\n",
    "  }\n",
    "\n",
    "  feature_reductions = {\n",
    "      'LDA': LinearDiscriminantAnalysis(),\n",
    "      'PCA': PCA(),\n",
    "      'None': None\n",
    "  }\n",
    "\n",
    "  # Run cross-validation and store results\n",
    "  results = []\n",
    "  for model_name, model in models.items():\n",
    "      for feature_set_name, feature_columns in feature_sets.items():\n",
    "          for reduction_name, reduction_func in feature_reductions.items():\n",
    "              print(f'\\nModel({model_name}) using feature({feature_set_name}) and feature reduction({reduction_name})\\n')\n",
    "              mean_accuracy, std_accuracy = k_fold_cross_validation(balanced_dataFrame, feature_columns, target_column, model, reduction_func, k=4)\n",
    "              results.append({\n",
    "                  'Model': model_name,\n",
    "                  'Feature Set': feature_set_name,\n",
    "                  'Feature Reduction': reduction_name,\n",
    "                  'Mean Accuracy': mean_accuracy,\n",
    "                  'Std Accuracy': std_accuracy\n",
    "                  })\n",
    "\n",
    "  results_df = pd.DataFrame(results)\n",
    "  return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03ufzOPP2lD8"
   },
   "source": [
    "# Random Student Set1\n",
    "Select 6 random Student and Ensure each student has an equal number of samples and visualize some features using pairplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjZ6Ujk4yQ-q"
   },
   "source": [
    "**Random Student Selection**: We begin by randomly selecting 6 students from the dataset. This ensures that our analysis is not biased towards any specific subset of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sj1XZHZJ2kRn",
    "outputId": "54f4f359-4bff-49c5-f83c-1b88a8b03823"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Get unique student IDs\n",
    "student_ids = data['student_id'].unique()\n",
    "\n",
    "# Randomly select 6 students\n",
    "selected_students = random.sample(list(student_ids), 6)\n",
    "print(f\"Selected Students: {selected_students}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAZRVMunyYuP"
   },
   "source": [
    "**Equal Number of Samples**: For each of the selected students, we ensure that an equal number of samples are used for further analysis. This step is crucial to maintain consistency and fairness in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAupIMdT224C",
    "outputId": "b650b76e-9871-402c-966c-b94e8a15fe75"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "filtered_data = data[data['student_id'].isin(selected_students)]\n",
    "\n",
    "# Ensure each student has an equal number of samples\n",
    "balanced_data = filtered_data.groupby('student_id').apply(lambda x: x.sample(n=filtered_data['student_id'].value_counts().min(), random_state=42)).reset_index(drop=True)\n",
    "balanced_data = shuffle(balanced_data, random_state=42)\n",
    "balanced_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Number of samples for each student in the balanced DataFrame:\")\n",
    "print(balanced_data['student_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDjnylUEyg7y"
   },
   "source": [
    "### **Pairplot Visualization**:\n",
    "Pairplots are used to visualize the relationships between different features for the selected students. This provides an intuitive and visual understanding of the data distribution and correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQbwjJ1myv1s"
   },
   "source": [
    "**MFCC features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g5Cc9q2KSDAW",
    "outputId": "a1153d3b-5810-4091-e506-b9fe5f660776"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "mfcc_features = [f'Mfcc_{i+1}' for i in range(13)]\n",
    "# Plot pair plot\n",
    "palette = sns.color_palette(\"tab10\", balanced_data['student_id'].nunique())\n",
    "sns.pairplot(balanced_data, hue='student_id', vars= mfcc_features, palette=palette)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcHWKUh0y3S1"
   },
   "source": [
    "**Spectral_Contrast features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gNrO9_IMTx5c",
    "outputId": "d27941bd-88db-4d00-d5a3-736f0ab2b4af"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "spectral_contrast_features = [f'Spectral_Contrast_{i+1}' for i in range(7)]\n",
    "# Plot pair plot\n",
    "palette = sns.color_palette(\"tab10\", balanced_data['student_id'].nunique())\n",
    "sns.pairplot(balanced_data, hue='student_id', vars= spectral_contrast_features, palette=palette)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVCfpVvuy8z0"
   },
   "source": [
    "**Time domain features**: Zero Crossing Rate and RMS Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "wNSX_KbBT85z",
    "outputId": "6e233398-4124-4aad-dc08-4d669254a20e"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "time_features = ['Zero_Crossing_Rate',\t'RMS_Energy']\n",
    "# Plot pair plot\n",
    "palette = sns.color_palette(\"tab10\", balanced_data['student_id'].nunique())\n",
    "sns.pairplot(balanced_data, hue='student_id', vars= time_features, palette=palette)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TCnvIqlSEtx"
   },
   "source": [
    "## **Classification and Analysis for Student Set1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTn_J7w0znQH"
   },
   "source": [
    "**Mapping Student IDs to Class Labels**: We create a mapping from student IDs to class labels. Each selected student is assigned a unique class label, starting from 0 up to the number of selected students minus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "785FzU-e3Ac_",
    "outputId": "d96f086e-7479-44af-afff-72d0c4aabd7e"
   },
   "outputs": [],
   "source": [
    "# Map student IDs to class labels (e.g., 0 to 5)\n",
    "class_mapping = {student_id: idx for idx, student_id in enumerate(selected_students)}\n",
    "balanced_data['class'] = balanced_data['student_id'].map(class_mapping)\n",
    "\n",
    "\n",
    "print(\"Balanced DataFrame with Class Column:\")\n",
    "balanced_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu3VqeQb3DWu"
   },
   "source": [
    "### Classification Process and Average Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ-d12ci1o8w"
   },
   "source": [
    "#### **Calling the Classification Function**\n",
    "The *Run_Classification* function is called with the balanced dataset (balanced_data) as its input. This function performs k-fold cross-validation for various combinations of classification models, feature sets, and feature reduction techniques.\n",
    "The *Result_DF* DataFrame now contains detailed performance metrics for various combinations of models, feature sets, and feature reduction techniques. This structured summary facilitates easy comparison and selection of the most effective approaches for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FqB5bxM13CdI",
    "outputId": "c4d7e9fe-c451-469b-8f2e-4f28e12ffd9d"
   },
   "outputs": [],
   "source": [
    "Result_DF = Run_Classification(balanced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJTYjj9E07ZY"
   },
   "source": [
    "#### **Sorting and Displaying Top Results**\n",
    "By sorting the results DataFrame by mean accuracy and displaying the top rows, we efficiently identify the best-performing combinations of models, feature sets, and feature reduction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "P2kpjEFWmA9h",
    "outputId": "2c43377f-de60-4bc5-8cb0-a7a969d20339"
   },
   "outputs": [],
   "source": [
    "df_sorted = Result_DF.sort_values(by='Mean Accuracy', ascending=False)\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulrFxEKR28xR"
   },
   "source": [
    "#### **Ploting Results**\n",
    "The line Plot_Results_Barchart(Result_DF) calls the Plot_Results_Barchart function and passes the Result_DF DataFrame as an argument. This function generates and displays bar charts that visually compare the performance of various classification models and feature reduction techniques based on the cross-validation results stored in Result_DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PelsQukwnoz9",
    "outputId": "647b0740-baa1-4e33-a142-cf74be4e55ef"
   },
   "outputs": [],
   "source": [
    "Plot_Results_Barchart(Result_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL-S7HK-aToS"
   },
   "source": [
    "# Random Student Set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lSa-okcSalQ4",
    "outputId": "53c0b34e-0f79-485b-9511-fad73b97a21c"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(8)\n",
    "\n",
    "# Get unique student IDs\n",
    "student_ids = data['student_id'].unique()\n",
    "\n",
    "# Randomly select 6 students\n",
    "selected_students = random.sample(list(student_ids), 6)\n",
    "print(f\"Selected Students: {selected_students}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBCpsnGVakN0",
    "outputId": "1b3b3a67-a8bf-418e-e5e4-82e49b2563c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "filtered_data = data[data['student_id'].isin(selected_students)]\n",
    "\n",
    "# Ensure each student has an equal number of samples\n",
    "balanced_data = filtered_data.groupby('student_id').apply(lambda x: x.sample(n=filtered_data['student_id'].value_counts().min(), random_state=42)).reset_index(drop=True)\n",
    "balanced_data = shuffle(balanced_data, random_state=42)\n",
    "balanced_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Number of samples for each student in the balanced DataFrame:\")\n",
    "print(balanced_data['student_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMxQlAyO3P8X"
   },
   "source": [
    "## Classification and Analysis for Student Set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "CtLoqfvGbY64",
    "outputId": "a6047d4e-680d-4241-8489-46f95d34aaf2"
   },
   "outputs": [],
   "source": [
    "# Map student IDs to class labels (e.g., 0 to 5)\n",
    "class_mapping = {student_id: idx for idx, student_id in enumerate(selected_students)}\n",
    "balanced_data['class'] = balanced_data['student_id'].map(class_mapping)\n",
    "\n",
    "print(\"Balanced DataFrame with Class Column:\")\n",
    "balanced_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nniy6G735nK"
   },
   "source": [
    "### Classification Process and Average Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUcnSjyQ4W18"
   },
   "source": [
    "#### **Calling the Classification Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KBx_wAgkakTN",
    "outputId": "dc96666e-3ad2-42ff-aeb5-6facafaede7a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Result_DF = Run_Classification(balanced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUXex_O64SfS"
   },
   "source": [
    "#### **Sorting and displaying Top Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sFQaO-_dmLQe",
    "outputId": "985d3338-574a-47be-cc01-371e7fec048d"
   },
   "outputs": [],
   "source": [
    "df_sorted = Result_DF.sort_values(by='Mean Accuracy', ascending=False)\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_gYqbAl4xen"
   },
   "source": [
    "#### **Ploting Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mkPXXpvWcAnr",
    "outputId": "aa8c94c3-e634-4929-d936-ad8eedb07a33"
   },
   "outputs": [],
   "source": [
    "Plot_Results_Barchart(Result_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qK0f9d-TcEhp"
   },
   "source": [
    "# Random Student Set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0Y9qniccNDY",
    "outputId": "c083bebb-2d62-4491-8075-391a5e14e57d"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1403)\n",
    "\n",
    "# Get unique student IDs\n",
    "student_ids = data['student_id'].unique()\n",
    "\n",
    "# Randomly select 6 students\n",
    "selected_students = random.sample(list(student_ids), 6)\n",
    "print(f\"Selected Students: {selected_students}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvbSdhqdcbP_",
    "outputId": "aac6f18f-ce38-4822-bcbe-a085713ef6fc"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "filtered_data = data[data['student_id'].isin(selected_students)]\n",
    "\n",
    "# Ensure each student has an equal number of samples\n",
    "balanced_data = filtered_data.groupby('student_id').apply(lambda x: x.sample(n=filtered_data['student_id'].value_counts().min(), random_state=42)).reset_index(drop=True)\n",
    "balanced_data = shuffle(balanced_data, random_state=42)\n",
    "balanced_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Number of samples for each student in the balanced DataFrame:\")\n",
    "print(balanced_data['student_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jC06xAU5YPb"
   },
   "source": [
    "## Classification and Analysis for Student Set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "HRJu48oBceKJ",
    "outputId": "e82c831f-7614-42b0-8648-f16b34089931"
   },
   "outputs": [],
   "source": [
    "# Map student IDs to class labels (e.g., 0 to 5)\n",
    "class_mapping = {student_id: idx for idx, student_id in enumerate(selected_students)}\n",
    "balanced_data['class'] = balanced_data['student_id'].map(class_mapping)\n",
    "\n",
    "print(\"Balanced DataFrame with Class Column:\")\n",
    "balanced_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9nhJg8H5l82"
   },
   "source": [
    "### Classification Process and Average Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VejlgQF57bN"
   },
   "source": [
    "#### **Calling the Classification Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rbQw7KokcjKB",
    "outputId": "5703320e-f9d1-449b-bf83-4dc902084936"
   },
   "outputs": [],
   "source": [
    "Result_DF = Run_Classification(balanced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWS_bPgL5wlD"
   },
   "source": [
    "#### **Sorting and displaying Top Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5ivAUdxmnE_o",
    "outputId": "d1987934-cb6a-4544-ff46-bcb860948ee1"
   },
   "outputs": [],
   "source": [
    "df_sorted = Result_DF.sort_values(by='Mean Accuracy', ascending=False)\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bxBzx6b6L1M"
   },
   "source": [
    "#### **Ploting Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PhZsS5Lzclh_",
    "outputId": "ce89d9a6-34e6-415f-e123-2d13838bd14b"
   },
   "outputs": [],
   "source": [
    "Plot_Results_Barchart(Result_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_mvciaHy1Ntj"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
